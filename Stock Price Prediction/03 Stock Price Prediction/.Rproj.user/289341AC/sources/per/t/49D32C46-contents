
# Load libraries

library(leaps)
library(car)
library(broom)

lmOut <- function(res, file="test.csv", ndigit=3, writecsv=T) {
  # If summary has not been run on the model then run summary
  if (length(grep("summary", class(res)))==0) res <- summary(res)
  
  co <- res$coefficients
  nvar <- nrow(co)
  ncol <- ncol(co)
  f <- res$fstatistic
  formatter <- function(x) format(round(x,ndigit),nsmall=ndigit)
  
  # This sets the number of rows before we start recording the coefficients
  nstats <- 4
  
  # G matrix stores data for output
  G <- matrix("", nrow=nvar+nstats, ncol=ncol+1)
  
  G[1,1] <- toString(res$call)
  
  # Save rownames and colnames
  G[(nstats+1):(nvar+nstats),1] <- rownames(co)
  G[nstats, 2:(ncol+1)] <- colnames(co)
  
  # Save Coefficients
  G[(nstats+1):(nvar+nstats), 2:(ncol+1)] <- formatter(co)
  
  # Save F-stat
  G[1,2] <- paste0("F(",f[2],",",f[3],")")
  G[2,2] <- formatter(f[1])
  
  # Save F-p value
  G[1,3] <- "Prob > P"
  G[2,3] <- formatter(1-pf(f[1],f[2],f[3]))
  
  # Save R2
  G[1,4] <- "R-Squared"
  G[2,4] <- formatter(res$r.squared)
  
  # Save Adj-R2
  G[1,5] <- "Adj-R2"
  G[2,5] <- formatter(res$adj.r.squared)
  
  print(G)
  if (writecsv) write.csv(G, file=file, row.names=F)
}

# Create single file with all regression outputs
regression_consolidated <- data.frame(ticker=character(0),alpha=character(0),beta=character(0),stringsAsFactors=FALSE)
consolidated_counter <- 0

companies <- list('fb','cof')
filepath_input <- "c:/users/riazu/Google Drive/Glucksman Fellowship/22 Stock Price Prediction/01 Regression Input/"
filepath_output <- "c:/users/riazu/Google Drive/Glucksman Fellowship/23 Stock Return Prediction/02 Prediction Output/"
filepath_reg_results <- "c:/users/riazu/Google Drive/Glucksman Fellowship/23 Stock Return Prediction/03 Regression Results/"

filename <- 'cof'

for (filename in companies) {

consolidated_counter <- consolidated_counter+1

data <- read.csv(paste0(filepath_input,filename,".csv"))
reg_data <- data[1:60,]

summary(reg_data)

# Create linear model
reg_dataa <- lm(reg_data$stock_return ~ reg_data$market_return)
summary(reg_dataa)

# Calculate VIFs
#vif(reg_dataa)

# Plot diagnostics
stdres <- rstandard(reg_dataa)
plot(fitted(reg_dataa),stdres,xlab="Fitted values",ylab="Standardized residuals")
title(main = "Fitted values vs. Standardized residuals")
qqnorm(stdres)
hist(stdres)

lmOut(reg_dataa, file=paste0(filepath_reg_results,filename," reg output.csv"))

regression_consolidated[consolidated_counter,'ticker'] <- filename
regression_consolidated[consolidated_counter,'alpha'] <- coef(reg_dataa)["(Intercept)"]
regression_consolidated[consolidated_counter,'beta'] <- coef(reg_dataa)["reg_data$market_return"]

# Predict stock price using model selected

predict_data <- data

predict_data1 <- predict(reg_dataa, predict_data)

predict_data$predict_stock_return <- predict_data1
predict_data$abnormal_return <- (predict_data$stock_return - predict_data$predict_stock_return)
predict_data$cumulative_ar[81] <- predict_data$abnormal_return[81]

for (time in 82:101) {
predict_data$cumulative_ar[time] <- cumsum(predict_data$abnormal_return[81]:predict_data$abnormal_return[time])
}


predict_data$newdate = as.Date(predict_data$date,origin = "1899-12-30")


jpeg(paste0(filepath_output,filename,'.jpg')
plot(predict_data$newdate,predict_data$abnormal_return,type="p",main=paste("Errors in ",filename," stock return prediction (CAPM)",sep=""),xlab="Date",ylab="Actual - Predicted stock return")
abline(v=predict_data$newdate[90],lty=2,lwd=3)
abline(h=0,lty=2,lwd=3)
dev.off()

write.csv(x=predict_data,file=paste0(filepath_output,filename,".csv"),row.names=TRUE)
write.csv(x=regression_consolidated,file=paste0(filepath_output,"regression_consolidated.csv"),row.names=TRUE)


}

